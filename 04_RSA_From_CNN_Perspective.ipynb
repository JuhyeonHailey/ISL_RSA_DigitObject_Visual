{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load sample image data\n",
    "sam_img = np.load('Val_data.npz')['val_X'] # Sample validation data as an exmaple.\n",
    "sam_img_num = sam_img.shape[0]\n",
    "num_sam = 10 # Sample validation data has 10 sample images per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,3))\n",
    "def img_proc(sam_img):\n",
    "    imgs_proc = np.zeros(sam_img.shape)\n",
    "    for idx, img in enumerate(sam_img):\n",
    "        img = np.asarray(img).astype('float32')\n",
    "        img = img - vgg_mean\n",
    "        imgs_proc[idx] = img[:,:,::-1]\n",
    "    return imgs_proc\n",
    "\n",
    "def get_layer_rep(li,imgs):\n",
    "    n_imgs = imgs.shape[0]\n",
    "    op = graph.get_tensor_by_name(relus[li]+':0')\n",
    "    ft_sh = (n_imgs, op.shape[1], op.shape[2], op.shape[3])\n",
    "    rep_ = np.zeros((ft_sh),dtype='float32')\n",
    "    for i,img in enumerate(imgs):\n",
    "        img = np.expand_dims(img,0)\n",
    "        rp = sess.run(op, {x:img, is_training:False})\n",
    "        rep_[i] = rp\n",
    "    rep_ = rep_.reshape(n_imgs,-1)\n",
    "    return rep_ # 16,1000 or 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('net-55.ckpt.meta')\n",
    "saver.restore(sess, 'net-55.ckpt')\n",
    "graph = tf.get_default_graph()\n",
    "# Load placeholder\n",
    "x = graph.get_tensor_by_name(\"Placeholder:0\") \n",
    "is_training = graph.get_tensor_by_name(\"Placeholder_2:0\")\n",
    "# Get relu layer\n",
    "relus = [op.name for op in graph.get_operations() if op.type=='Relu']\n",
    "relus = relus[:14] + ['fc8/Conv2D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depth = 15\n",
    "cnnrdms = np.zeros((depth,16,16))\n",
    "sam_img_proc = img_proc(sam_img) # Image preprocessing \n",
    "for li in range(depth):\n",
    "    rep_ = get_layer_rep(li,sam_img_proc)\n",
    "    # PCA\n",
    "    std_ = StandardScaler()\n",
    "    x_scld = std_.fit_transform(rep_)\n",
    "    pca = PCA(n_components=0.90)\n",
    "    pca.fit(x_scld)\n",
    "    x_ = pca.transform(x_scld)\n",
    "    # Average to 16x16\n",
    "    x_16 = np.zeros((16,x_.shape[1]))\n",
    "    for ci in range(16):\n",
    "        x_16[ci] = np.mean(x_[ci*num_sam:(ci+1)*num_sam],axis=0)\n",
    "    cnnrdms[li] = 1-np.corrcoef(x_16.transpose(), rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize CNN RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mask \n",
    "mask = np.zeros((16,16))\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Title list\n",
    "tlist = []\n",
    "for li in range(1,14):\n",
    "    tlist.append('Conv '+str(li))\n",
    "tlist += ['FC','Output']\n",
    "# Tickslabels\n",
    "labels = ['Zero','One','Two','Three','Four','Five','Six','Seven','Eight',\n",
    "          'Nine','Bed','Bird','Cat','Dog','House','Tree']\n",
    "# Default font size\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot RDM\n",
    "# Autorange\n",
    "f,axes = plt.subplots(3,5, figsize=(38,20))\n",
    "ax = axes.flat\n",
    "for li in range(15):\n",
    "    ax[li].set_title(tlist[li],fontsize=40)\n",
    "    sns.heatmap(cnnrdms[li],mask=mask,cmap='jet',ax=ax[li],xticklabels=labels,yticklabels=labels,square=True,cbar=True) #,vmin=0,vmax=2\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Min 0 Max 2\n",
    "f,axes = plt.subplots(3,5, figsize=(38,20))\n",
    "ax = axes.flat\n",
    "for li in range(15):\n",
    "    ax[li].set_title(tlist[li],fontsize=40)\n",
    "    sns.heatmap(cnnrdms[li],mask=mask,cmap='jet',ax=ax[li],xticklabels=labels,yticklabels=labels,square=True,vmin=0,vmax=2)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSA between neural RDM and CNN RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iu = np.triu_indices(16,1)\n",
    "def rsa(neural_rdm,cnnrdm):\n",
    "    rho, p = stats.spearmanr(neural_rdm[iu],cnnrdm[iu])\n",
    "    return rho, p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load sample neural RDM made by '03_MVPA_Neural_RDMs.ipynb'\n",
    "l = np.load('Sample_Neural_RDM.npz',allow_pickle=True)\n",
    "brain_rdm = l['rdm']\n",
    "brain_inform_list = l['info_list']\n",
    "\n",
    "# Number of searchlight voxels\n",
    "nvv = brain_rdm.shape[0]\n",
    "\n",
    "# RSA\n",
    "rsa_rslt = np.zeros((depth,64,76,64))\n",
    "rsa_rslt_pval = np.zeros((depth,64,76,64))\n",
    "for li in range(depth):\n",
    "    vol_rho = np.zeros((64,76,64))\n",
    "    vol_pval = np.zeros((64,76,64))\n",
    "    for vi in range(nvv):\n",
    "        idx = brain_inform_list[vi][1]\n",
    "        neural_rdm = brain_rdm[vi]\n",
    "        vol_rho[idx], vol_pval[idx] = rsa(neural_rdm, cnnrdms[li])\n",
    "    rsa_rslt[li], rsa_rslt_pval[li] = vol_rho, vol_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer assignment map\n",
    "- In this tutorial, you would use rho values rather than t-statistic from group data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_threshold = 0.05\n",
    "rsa_rslt[(rsa_rslt_pval > p_threshold)] = 0 # uncorrected p-values used in this sample code\n",
    "# Mask \n",
    "tmpsum = np.sum((rsa_rslt>0),axis=0)\n",
    "tmpsum2 = np.sum((rsa_rslt<0),axis=0)\n",
    "msk_idx = np.where((tmpsum > 0)&(tmpsum2!=15))\n",
    "# Maximally similar layer\n",
    "max_info = np.argmax(rsa_rslt.transpose(1,2,3,0)[msk_idx],axis=1) # vec,depth\n",
    "max_info += 1\n",
    "# Assign\n",
    "assign_map = np.zeros((64,76,64))\n",
    "assign_map[msk_idx] = max_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to save assigment map obtained from sample data, you can run this cell.\n",
    "# Please set the path to save.\n",
    "savepath = '/path/to/save/assigned_map.nii'\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "affine = np.array([[   3. ,   -0. ,   -0. ,  -94.5],\n",
    "       [  -0. ,    3. ,   -0. , -130.5],\n",
    "       [   0. ,    0. ,    3. ,  -76.5],\n",
    "       [   0. ,    0. ,    0. ,    1. ]])\n",
    "\n",
    "def save_nifti(vol, savepath, zero_to_nan=True):\n",
    "    if zero_to_nan:\n",
    "        vol[(vol==0)] = np.nan\n",
    "    img1 = nib.Nifti1Image(vol,affine=affine)\n",
    "    nib.save(img1,savepath)\n",
    "    \n",
    "save_nifti(assign_map, savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save CNN RDMs for running the code '06-1_Cosine_CNN_Code'\n",
    "np.savez('Sample_CNN_RDM.npz',cnnrdms=cnnrdms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
