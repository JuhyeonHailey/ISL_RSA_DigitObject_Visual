{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To visualize the unit activations from CNN layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load sample image set\n",
    "sam_img = np.load('Val_data.npz')['val_X'] # Sample validation data as an exmaple.\n",
    "sam_img_num = sam_img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1,1,3))\n",
    "def img_proc(sam_img):\n",
    "    imgs_proc = np.zeros(sam_img.shape)\n",
    "    for idx, img in enumerate(sam_img):\n",
    "        img = np.asarray(img).astype('float32')\n",
    "        img = img - vgg_mean\n",
    "        imgs_proc[idx] = img[:,:,::-1]\n",
    "    return imgs_proc\n",
    "\n",
    "def get_layer_rep(li,imgs,method=None):\n",
    "    n_imgs = imgs.shape[0]\n",
    "    op = graph.get_tensor_by_name(relus[li]+':0')\n",
    "    ft_sh = (n_imgs, op.shape[1], op.shape[2], op.shape[3])\n",
    "    rep_ = np.zeros((ft_sh),dtype='float32')\n",
    "    for i,img in enumerate(imgs):\n",
    "        img = np.expand_dims(img,0)\n",
    "        rp = sess.run(op, {x:img, is_training:False})\n",
    "        rep_[i] = rp\n",
    "    rep_ = rep_.reshape(n_imgs,-1)\n",
    "    return rep_\n",
    "\n",
    "def scale_01(x):\n",
    "    rg = (np.max(x) - np.min(x))\n",
    "    st = x - np.min(x)\n",
    "    return st / rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('net-55.ckpt.meta')\n",
    "saver.restore(sess, 'net-55.ckpt')\n",
    "graph = tf.get_default_graph()\n",
    "# Load placeholder\n",
    "x = graph.get_tensor_by_name(\"Placeholder:0\") \n",
    "is_training = graph.get_tensor_by_name(\"Placeholder_2:0\")\n",
    "# Get relu layer\n",
    "relus = [op.name for op in graph.get_operations() if op.type=='Relu']\n",
    "relus = relus[:14] + ['fc8/Conv2D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Labels for t-SNE plot\n",
    "labels = []\n",
    "for ci in range(16):\n",
    "    for si in range(10): # Number of sample\n",
    "        labels.append(ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting parameters\n",
    "color_list = ['#E07F81','#AC84C8','#97C9EC','#7CBC75','#EDEC2E','#E1A822','#DA592C','#8A319B','#3D59B1','#6294D3','#82BEA6','#4C888E','#418335','#97C225','#9A9A33','#724821']\n",
    "tlist = [] # Title list\n",
    "for li in range(1,14):\n",
    "    tlist.append('Conv '+str(li))\n",
    "tlist += ['FC','Output']\n",
    "label_list = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six',\n",
    "              'Seven', 'Eight', 'Nine', 'Bed', 'Bird', 'Cat', 'Dog',\n",
    "              'House', 'Tree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depth = 15 # CNN model depth\n",
    "sam_img_proc = img_proc(sam_img) # Image preprocessing\n",
    "for li in range(depth):\n",
    "    features = get_layer_rep(li,sam_img_proc) \n",
    "    features = features.reshape(sam_img_num,-1)\n",
    "    tsne = TSNE(n_components=2,perplexity=30).fit_transform(features) # You can tune perplexity.\n",
    "\n",
    "    tx = tsne[:,0]\n",
    "    ty = tsne[:,1]\n",
    "\n",
    "    tx = scale_01(tx)\n",
    "    ty = scale_01(ty)\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.title(tlist[li],fontsize=20)\n",
    "\n",
    "    for ci in range(16):\n",
    "        indices = [i for i, l in enumerate(labels) if l == ci]\n",
    "        curr_tx = np.take(tx, indices)\n",
    "        curr_ty = np.take(ty, indices)\n",
    "        plt.scatter(curr_tx, curr_ty, c=color_list[ci], label=label_list[ci])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw input data features\n",
    "imglen = 224*224*3\n",
    "features = sam_img_proc.reshape(sam_img_num,imglen).copy()\n",
    "tsne = TSNE(n_components=2,perplexity=30).fit_transform(features)\n",
    "\n",
    "tx = tsne[:,0]\n",
    "ty = tsne[:,1]\n",
    "\n",
    "tx = scale_01(tx)\n",
    "ty = scale_01(ty)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.title('Input',fontsize=15)\n",
    "\n",
    "for ci in range(16):\n",
    "    indices = [i for i, l in enumerate(labels) if l == ci]\n",
    "    curr_tx = np.take(tx, indices)\n",
    "    curr_ty = np.take(ty, indices)\n",
    "    plt.scatter(curr_tx, curr_ty, c=color_list[ci], label=label_list[ci])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
